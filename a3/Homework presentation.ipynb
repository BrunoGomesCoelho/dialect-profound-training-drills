{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Assignment 3 </center></h1>\n",
    "\n",
    "Bruno Gomes Coelho - bruno.gomes.coelho@usp.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "\n",
    "- - - \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> <center> Machine Learning & NN </center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## a) Adam optimizer  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### i) Briefly explain (you don’t need to prove mathematically, just give an intuition) how using **m** stops the updates from varyingas much and why this low variance may be helpful to learning, overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Helps with local minima\n",
    "- Helps with saddle points\n",
    "- \"Cancelling\" zig zags\n",
    "- Closer to the true gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ii) Why (does dividing by $ \\sqrt{v} $)  help with learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Smaller gradientes will will pick up, proportionally, more velocity -> will help with \"flat\" terrain;\n",
    "- In general, the magnitude of the updates are invariant to scaling -> we control using just the lr \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## b) Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### i) What must γ equal in terms of $ p_{drop} $ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "γ = $ \\frac{1}{1 - p_{drop}} $\n",
    "\n",
    "This is basically the cs231n dropout trick better explained :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ii) Why should we apply dropout during training but not during evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We want **deterministic** test time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> <center> Neural Transition-Based Dependecy Parsing</center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## a)  Dependence parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# ![image](2a.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## b)  A sentence containing n words will be parsed in how many steps (in terms of n)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2n - A cada iteração ou colocamos na stack ou removemos do buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center> parser_transition.py </center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def __init__():\n",
    "    self.stack = [\"ROOT\"]\n",
    "    self.buffer = [x for x in self.sentence]\n",
    "    self.dependencies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-622d3b2d0cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mget_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"LA\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFIRST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RA\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSECOND\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mtransition\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"S\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transition' is not defined"
     ]
    }
   ],
   "source": [
    "def parse_step(self, transition):\n",
    "    ### YOUR CODE HERE (~7-10 Lines)\n",
    "    ### TODO:\n",
    "    ###     Implement a single parsing step, i.e. the logic for the following as\n",
    "    ###     described in the pdf handout:\n",
    "    ###         1. Shift\n",
    "    ###         2. Left Arc\n",
    "    ###         3. Right Arc\n",
    "\n",
    "    # Helper variables for readibility\n",
    "    FIRST, SECOND = -1, -2\n",
    "    get_remove = {\"RA\": FIRST, \"LA\": SECOND}\n",
    "    get_head = {\"LA\": FIRST, \"RA\": SECOND}\n",
    "\n",
    "    if transition == \"S\":\n",
    "        word = self.buffer.pop(0)\n",
    "        self.stack.append(word)\n",
    "\n",
    "    if transition in [\"LA\", \"RA\"]:\n",
    "        head = self.stack[get_head[transition]]\n",
    "        remove = self.stack.pop(get_remove[transition])\n",
    "        self.dependencies.append((head, remove)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def minibatch_parse(sentences, model, batch_size):\n",
    "\n",
    "    dependencies = []\n",
    "    ### YOUR CODE HERE (~8-10 Lines)\n",
    "    ### TODO:\n",
    "    ###     Implement the minibatch parse algorithm as described in the pdf handout\n",
    "    ###\n",
    "    ###     Note: A shallow copy (as denoted in the PDF) can be made with the \"=\" sign in python, e.g.\n",
    "    ###                 unfinished_parses = partial_parses[:].\n",
    "\n",
    "    partial_parses = [PartialParse(sent) for sent in sentences]\n",
    "    unfinished_parses = partial_parses[:]\n",
    "\n",
    "    while unfinished_parses:\n",
    "        minibatch = unfinished_parses[:batch_size]\n",
    "        transitions = model.predict(minibatch)\n",
    "\n",
    "        for partial_parser, transation in zip(minibatch, transitions):\n",
    "            partial_parser.parse_step(transation)\n",
    "            if (not partial_parser.buffer) and len(partial_parser.stack) == 1:\n",
    "                unfinished_parses.remove(partial_parser)\n",
    "\n",
    "    return [pp.dependencies for pp in partial_parses]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center> parser_model.py </center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def __init__(self, embeddings, n_features=36,\n",
    "             hidden_size=200, n_classes=3, dropout_prob=0.5):\n",
    "    ### YOUR CODE HERE (~5 Lines)\n",
    "    ### TODO:\n",
    "    ###     1) Construct `self.embed_to_hidden` linear layer, initializing the weight matrix\n",
    "    ###         with the `nn.init.xavier_uniform_` function with `gain = 1` (default)\n",
    "    ###     2) Construct `self.dropout` layer.\n",
    "    ###     3) Construct `self.hidden_to_logits` linear layer, initializing the weight matrix\n",
    "    ###         with the `nn.init.xavier_uniform_` function with `gain = 1` (default)\n",
    "    ###\n",
    "    self.embed_to_hidden = nn.Linear(self.embed_size*self.n_features, \n",
    "                                     self.hidden_size)\n",
    "    nn.init.xavier_uniform_(self.embed_to_hidden.weight, gain=1)\n",
    "\n",
    "    self.dropout = nn.Dropout(self.dropout_prob)\n",
    "\n",
    "    self.hidden_to_logits = nn.Linear(self.hidden_size, self.n_classes)\n",
    "    nn.init.xavier_uniform_(self.hidden_to_logits.weight, gain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def embedding_lookup(self, t):\n",
    "    ### YOUR CODE HERE (~1-3 Lines)\n",
    "    ### TODO:\n",
    "    ###     1) Use `self.pretrained_embeddings` to lookup the embeddings for the input tokens in `t`.\n",
    "    ###     2) After you apply the embedding lookup, you will have a tensor shape (batch_size, n_features, embedding_size).\n",
    "    ###         Use the tensor `view` method to reshape the embeddings tensor to (batch_size, n_features * embedding_size)\n",
    "    ###\n",
    "    ### Note: In order to get batch_size, you may need use the tensor .size() function:\n",
    "    ###         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.size\n",
    "    x = self.pretrained_embeddings(t)\n",
    "    x = x.view(x.size()[0], -1)\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def forward(self, t):\n",
    "    ###  YOUR CODE HERE (~3-5 lines)\n",
    "    ### TODO:\n",
    "    ###     1) Apply `self.embedding_lookup` to `t` to get the embeddings\n",
    "    ###     2) Apply `embed_to_hidden` linear layer to the embeddings\n",
    "    ###     3) Apply relu non-linearity to the output of step 2 to get the hidden units.\n",
    "    ###     4) Apply dropout layer to the output of step 3.\n",
    "    ###     5) Apply `hidden_to_logits` layer to the output of step 4 to get the logits.\n",
    "    ###\n",
    "    ### Note: We do not apply the softmax to the logits here, because\n",
    "    ### the loss function (torch.nn.CrossEntropyLoss) applies it more efficiently.\n",
    "    ###\n",
    "    ### Please see the following docs for support:\n",
    "    ###     ReLU: https://pytorch.org/docs/stable/nn.html?highlight=relu#torch.nn.functional.relu\n",
    "\n",
    "    x = self.embedding_lookup(t)\n",
    "    x = self.embed_to_hidden(x)\n",
    "    x = nn.functional.relu(x)\n",
    "    x = self.dropout(x)\n",
    "    logits = self.hidden_to_logits(x)\n",
    "\n",
    "    ### END YOUR CODE\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><center> run.py </center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def train(parser, train_data, dev_data, output_path, \n",
    "          batch_size=1024, n_epochs=10, lr=0.0005):\n",
    "    ### YOUR CODE HERE (~2-7 lines)\n",
    "    ### TODO:\n",
    "    ###      1) Construct Adam Optimizer in variable `optimizer`\n",
    "    ###      2) Construct the Cross Entropy Loss Function in variable `loss_func`\n",
    "    ###\n",
    "\n",
    "    optimizer = optim.Adam(parser.model.parameters())\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    ### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def train_for_epoch(parser, train_data, dev_data, optimizer, loss_func, batch_size):\n",
    "    parser.model.train() # Places model in \"train\" mode, i.e. apply dropout layer\n",
    "    n_minibatches = math.ceil(len(train_data) / batch_size)\n",
    "    loss_meter = AverageMeter()\n",
    "\n",
    "    with tqdm(total=(n_minibatches)) as prog:\n",
    "        for i, (train_x, train_y) in enumerate(minibatches(train_data, batch_size)):\n",
    "            optimizer.zero_grad()   # remove any baggage in the optimizer\n",
    "            loss = 0. # store loss for this batch here\n",
    "            train_x = torch.from_numpy(train_x).long()\n",
    "            train_y = torch.from_numpy(train_y.nonzero()[1]).long()\n",
    "\n",
    "            ### YOUR CODE HERE (~5-10 lines)\n",
    "            ### TODO:\n",
    "            ###      1) Run train_x forward through model to produce `logits`\n",
    "            ###      2) Use the `loss_func` parameter to apply the PyTorch CrossEntropyLoss function.\n",
    "            ###         This will take `logits` and `train_y` as inputs. It will output the CrossEntropyLoss\n",
    "            ###         between softmax(`logits`) and `train_y`. Remember that softmax(`logits`)\n",
    "            ###         are the predictions (y^ from the PDF).\n",
    "            ###      3) Backprop losses\n",
    "            ###      4) Take step with the optimizer\n",
    "            ### Please see the following docs for support:\n",
    "            ###     Optimizer Step: https://pytorch.org/docs/stable/optim.html#optimizer-step\n",
    "            logits = model.forward(train_x)\n",
    "            loss = loss_func(logits, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Resultado final: \n",
    "- test UAS: 89.02                                                  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### f) Different parsing mistakes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![image](2f1.jpg)\n",
    "\n",
    "Verbal Phrase\n",
    "Heading -> Fearing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![image](2f2.jpg)\n",
    "\n",
    "Coordination Attachment\n",
    "rush -> rescue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![image](2f3.jpg)\n",
    "\n",
    "Prepositional Phrase\n",
    "guy -> Midland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![image](2f4.jpg)\n",
    "\n",
    "Modifier Attachment\n",
    "crucial -> most"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center> Thanks :) </center> "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  },
  "rise": {
   "enable_chalkboard": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
